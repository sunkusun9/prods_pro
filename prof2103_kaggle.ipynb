{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5338a7f",
   "metadata": {},
   "source": [
    "Python: 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
    "\n",
    "|모듈|버젼|\n",
    "|----|----|\n",
    "|pandas|0.25.1|\n",
    "|numpy|1.18.5|\n",
    "|sklearn|0.21.3|\n",
    "|scipy|1.5.2|\n",
    "|mlxtend|0.15.0.0|\n",
    "|statsmodels|0.11.1|\n",
    "|imblearn|0.5.0|\n",
    "|xgboost|0.80|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1b72a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "imblearn 0.5.0\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy \n",
    "import mlxtend\n",
    "import statsmodels\n",
    "import imblearn\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, imblearn, xgb]:\n",
    "    print(i.__name__,  i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605c3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61a1137",
   "metadata": {},
   "source": [
    "## 문제 8번, Kaggle 형 20점\n",
    "\n",
    "이전 문제들에서 ‘에너지 생산량에 log를 취한 값(generate_log)’을 예측하는 모델을 만들어 보았다. \n",
    "\n",
    "본 문제에서는 ‘generate_log’를 예측하는 최고의 성능을 내는 회귀 모델을 자유롭게 구현하도록 한다. \n",
    "\n",
    "알고리즘, 파라미터, 변수 선정 등 다양한 시도를 통해 더 높은 정확도를 보이는 모델을 개발하시오.\n",
    "\n",
    "- ‘prof2103_2_data.csv’의 1월부터 8월까지 데이터를 train set으로 활용한다.\n",
    "   (이외 주어진 모든 데이터셋 활용 가능)\n",
    "\n",
    "- ‘prof2103_2_data.csv’의 9월부터 12월까지 데이터를 test set으로 사용한다.\n",
    "\n",
    "(이 데이터들의 에너지 생산량(generate) 컬럼은 모두 결측치이다.)\n",
    "\n",
    "- 가장 높은 성능을 가지는 예측모델을 개발하는 것이 목표이며, 성능 평가 기준은 RMSE(root mean square error, 아래 식 참고)이다.\n",
    "\n",
    "\n",
    "$RMSE=\\sqrt{\\frac{1}{N}\\sum_{t=1}^n(\\hat{y_i} - y_i)^2}$     ($\\hat{y}$  : 예측값, $y$: 실제값)\n",
    "\n",
    "**제출 ① - 예측값  (answer6.csv)**\n",
    "\n",
    "-\t‘prof2103_2_data.csv’의 9~12월 데이터(101,525행)에 대한 ‘generate_log’ 예측값\n",
    "\n",
    "-\t다음 양식에 따라 제출\n",
    "\n",
    "|datetime|user_id|generate_log|\n",
    "|--------|-------|------------|\n",
    "|2019-09-01 00:00:00|568|1.23|\n",
    "|2019-09-01 00:00:00|689|4.56|\n",
    "|2019-09-01 00:00:00|482|7.89|\n",
    "|…|…|…|\n",
    "|2019-12-31 23:00:00|1122|1.35|\n",
    "\n",
    "-\t구분자(Seperator)를 Comma(,)로 하는 txt 확장자 파일을 생성하여 업로드\n",
    "\n",
    "**제출 ② – answer6 소스 코드**\n",
    "\n",
    "(브라이틱스: answer8_이름.json, 파이썬: answer8_이름.py / answer8_이름.ipynb)\n",
    "\n",
    "- 캐글형 문제에 대한 소스 코드를 따로 작성\n",
    "- 모델 내, 데이터셋 로드부터 예측결과 조회까지 정상수행여부 확인 후 업로드\n",
    "\n",
    "**제출** 위의 ①, ②에 해당하는 파일들(예측 결과, 풀이 모델)을 answer8_이름.zip 으로 압축하여 시스템에 첨부하시오. \n",
    "\n",
    "(2개 파일 중, 하나라도 누락 시 0점 처리)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2f3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀이에 필요한 데이터셋을 불러 옵니다.\n",
    "\n",
    "df_weather = pd.read_csv('data/prof2103_2_weather.csv', parse_dates=['datetime'])\n",
    "df_meta = pd.read_csv('data/prof2103_2_building_metadata.csv')\n",
    "df_data = pd.read_csv('data/prof2103_2_data.csv', parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73d43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리에서 Interpolation을 들고 옵니다.\n",
    "df_weather.sort_values(['datetime'], inplace=True)\n",
    "X_itp = ['temperature', 'cloud', 'dew_point', 'rain_hourly', 'air_pressure', 'wind_direction']\n",
    "\n",
    "def interpolate(df):\n",
    "    df_ = df[X_itp].copy()\n",
    "    for i, col in enumerate(X_itp):\n",
    "        if df_[col].notna().sum() > 0:\n",
    "            df_.iloc[[0, -1], i] = df_.loc[df_[col].notna(), col].iloc[[0, -1]].values\n",
    "    return df_.interpolate()\n",
    "\n",
    "df_weather[X_itp] = df_weather.groupby('region_id')[X_itp].apply(\n",
    "    lambda x: pd.DataFrame(interpolate(x), index=x.index, columns=x.columns)\n",
    ")\n",
    "\n",
    "# 구간화를 통한 보정 로직을 들고 옵니다.\n",
    "df_weather['cloud'] = pd.cut(\n",
    "    df_weather['cloud'], \n",
    "    bins=[0, 2, 4, 6, 8, np.inf], \n",
    "    right=False, \n",
    "    labels=[0, 2, 4, 6, 8]\n",
    ").astype(float)\n",
    "\n",
    "# weather의 시간 조정을 합니다, data 데이터프레임과 결합을 위한\n",
    "s_temp_mean = df_weather.assign(\n",
    "    hour = lambda x: x['datetime'].dt.hour\n",
    ").groupby(['region_id', 'hour'])['temperature'].mean()\n",
    "df_temp_mean = s_temp_mean.reset_index()\n",
    "\n",
    "s_shift_time = df_temp_mean.groupby('region_id')\\\n",
    "                    .apply(\n",
    "                        lambda x: pd.Timedelta(hours=14 - x.set_index('hour')['temperature'].idxmax())\n",
    "                    )\n",
    "\n",
    "# datetime은 시스템 예약어라 dictionary unpacking을 통해서도 넣어봅니다.\n",
    "df_weather_s = df_weather.assign(\n",
    "    **{'datetime': lambda x: x['datetime'] + x['region_id'].map(s_shift_time)}\n",
    ")\n",
    "\n",
    "df_data_meta = df_data.merge(\n",
    "    df_meta, on='user_id'\n",
    ")\n",
    "\n",
    "df_data_weather = df_data_meta.merge(df_weather_s, on=['datetime', 'region_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b770d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자형 파생변수를 만들어 봅니다.\n",
    "df_data_weather['month'] = df_data_weather['datetime'].dt.month\n",
    "df_data_weather['hour'] = df_data_weather['datetime'].dt.hour\n",
    "df_data_weather['day'] = df_data_weather['datetime'].dt.day\n",
    "\n",
    "# log 파생변수를 만듭니다.\n",
    "df_data_weather['area_log'] = np.log(df_data_weather['area'] + 1)\n",
    "df_data_weather['num_floors_log'] = np.log(df_data_weather['num_floors'] + 1)\n",
    "\n",
    "# 타깃 변수를 만듭니다.\n",
    "df_data_weather['generate_log'] = np.log(df_data_weather['generate'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc62b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_data_weather.loc[df_data_weather['datetime'] < \"2019-09-01\"].copy()\n",
    "df_test = df_data_weather.loc[df_data_weather['datetime'] >= \"2019-09-01\"].copy()\n",
    "df_test[['temperature', 'dew_point', 'wind_direction']] = \\\n",
    "        df_test.groupby('region_id')[['temperature', 'dew_point', 'wind_direction']].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67fbe2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree 계열의 모델을 사용하려 합니다. 나머지 결측치는 일반 수치와 구분이 되도록 -1000으로 합니다.\n",
    "df_train2 = df_train.fillna(-1000)\n",
    "df_test2 = df_test.fillna(-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36c57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# test가 시점을 기준으로 나누어졌으니 \n",
    "# 검증셋도 동일하게 시점을 기준으로 나눕니다.\n",
    "df_val_train = df_train2.loc[df_train2['datetime'] < '2019-07-01']\n",
    "df_val_test = df_train2.loc[df_train2['datetime'] >= '2019-07-01']\n",
    "\n",
    "# 검증 함수입니다.\n",
    "def evaluate(reg, X):\n",
    "    reg.fit(df_val_train[X], df_val_train['generate_log'])\n",
    "    rmse_train = mean_squared_error(df_val_train['generate_log'], reg.predict(df_val_train[X]))\n",
    "    rmse_test = mean_squared_error(df_val_test['generate_log'], reg.predict(df_val_test[X]))\n",
    "    return rmse_train, rmse_test\n",
    "\n",
    "# 제출 함수입니다.\n",
    "def answer(reg, X):\n",
    "    reg.fit(df_train2[X], df_train2['generate_log'])\n",
    "    df_ans = pd.DataFrame(\n",
    "        {\n",
    "            'datetime': df_test['datetime'],\n",
    "            'user_id': df_test['user_id'],\n",
    "            'generate_log': reg.predict(df_test[X])\n",
    "        }\n",
    "    )\n",
    "    df_ans.to_csv('answer8.csv', index=None)\n",
    "    return df_ans\n",
    "\n",
    "# 범주형 입력 변수입니다.\n",
    "X_cat = ['region_id', 'usage']\n",
    "# 수치형 입력 변수입니다.\n",
    "X_num = [i for i in df_train2.columns if i not in X_cat and i not in ['datetime', 'user_id', 'generate', 'generate_log']]\n",
    "\n",
    "df_solution = pd.read_csv('data/prof2103_2_data_solution.csv')\n",
    "df_solution.sort_values(['datetime', 'user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "326740bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.819101521068044e-05, 0.9209511874240275)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 모델입니다.\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X_num_dt = [i for i in X_num if i not in ['area_log', 'num_floors_log', 'month', 'day']]\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), X_cat),\n",
    "    ('pt', 'passthrough', X_num_dt)\n",
    "])\n",
    "\n",
    "X_dt = X_cat + X_num_dt\n",
    "reg_dt = DecisionTreeRegressor(random_state=123)\n",
    "evaluate(reg_dt, X_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953974bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ans_dt = answer(reg_dt, X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236bb39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4762815191303997"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error( \n",
    "    np.log(df_solution['generate'] + 1),\n",
    "    df_ans_dt.sort_values(['datetime', 'user_id'])['generate_log']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec19d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이후 개선 과정은 내일 오전에 해보겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
